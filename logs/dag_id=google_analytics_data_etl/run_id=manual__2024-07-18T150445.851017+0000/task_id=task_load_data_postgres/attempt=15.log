[2024-07-19T14:00:18.053+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: google_analytics_data_etl.task_load_data_postgres manual__2024-07-18T15:04:45.851017+00:00 [queued]>
[2024-07-19T14:00:18.062+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: google_analytics_data_etl.task_load_data_postgres manual__2024-07-18T15:04:45.851017+00:00 [queued]>
[2024-07-19T14:00:18.063+0000] {taskinstance.py:2171} INFO - Starting attempt 15 of 15
[2024-07-19T14:00:18.081+0000] {taskinstance.py:2192} INFO - Executing <Task(PostgresOperator): task_load_data_postgres> on 2024-07-18 15:04:45.851017+00:00
[2024-07-19T14:00:18.089+0000] {standard_task_runner.py:60} INFO - Started process 108 to run task
[2024-07-19T14:00:18.094+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'google_analytics_data_etl', 'task_load_data_postgres', 'manual__2024-07-18T15:04:45.851017+00:00', '--job-id', '250', '--raw', '--subdir', 'DAGS_FOLDER/google_analytics_data_etl/google_analytics_data_etl.py', '--cfg-path', '/tmp/tmpo_gtl32m']
[2024-07-19T14:00:18.096+0000] {standard_task_runner.py:88} INFO - Job 250: Subtask task_load_data_postgres
[2024-07-19T14:00:18.161+0000] {task_command.py:423} INFO - Running <TaskInstance: google_analytics_data_etl.task_load_data_postgres manual__2024-07-18T15:04:45.851017+00:00 [running]> on host 3d44d7374020
[2024-07-19T14:00:18.257+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='google_analytics_data_etl' AIRFLOW_CTX_TASK_ID='task_load_data_postgres' AIRFLOW_CTX_EXECUTION_DATE='2024-07-18T15:04:45.851017+00:00' AIRFLOW_CTX_TRY_NUMBER='15' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-07-18T15:04:45.851017+00:00'
[2024-07-19T14:00:18.259+0000] {sql.py:276} INFO - Executing: INSERT INTO event (event_id, event_name, event_bundle_sequence_id, event_user_pseudo_count) VALUES (0, 'first_open', '1', 4),(1, 'os_update', '15', 1),(2, 'os_update', '3', 1),(3, 'os_update', '4', 1),(4, 'screen_view', '10', 2),(5, 'screen_view', '11', 3),(6, 'screen_view', '12', 10),(7, 'screen_view', '13', 1),(8, 'screen_view', '15', 2),(9, 'screen_view', '16', 1),(10, 'screen_view', '2', 12),(11, 'screen_view', '26', 2),(12, 'screen_view', '27', 3),(13, 'screen_view', '3', 7),(14, 'screen_view', '4', 10),(15, 'screen_view', '44', 2),(16, 'screen_view', '45', 3),(17, 'screen_view', '46', 5),(18, 'screen_view', '47', 2),(19, 'screen_view', '5', 16),(20, 'screen_view', '6', 33),(21, 'screen_view', '60', 2),(22, 'screen_view', '61', 3),(23, 'screen_view', '62', 2),(24, 'screen_view', '69', 4),(25, 'screen_view', '7', 18),(26, 'screen_view', '70', 2),(27, 'screen_view', '71', 1),(28, 'select_content', '12', 2),(29, 'select_content', '27', 1),(30, 'select_content', '45', 1),(31, 'select_content', '46', 2),(32, 'select_content', '5', 4),(33, 'select_content', '6', 3),(34, 'select_content', '62', 1),(35, 'select_content', '7', 4),(36, 'select_content', '70', 1),(37, 'session_start', '10', 1),(38, 'session_start', '11', 1),(39, 'session_start', '12', 1),(40, 'session_start', '15', 1),(41, 'session_start', '2', 4),(42, 'session_start', '26', 1),(43, 'session_start', '3', 1),(44, 'session_start', '4', 2),(45, 'session_start', '44', 1),(46, 'session_start', '60', 1),(47, 'session_start', '69', 1),(48, 'session_start', '70', 1),(49, 'session_start', '8', 1),(50, 'user_engagement', '11', 1),(51, 'user_engagement', '12', 5),(52, 'user_engagement', '13', 1),(53, 'user_engagement', '16', 1),(54, 'user_engagement', '2', 7),(55, 'user_engagement', '27', 2),(56, 'user_engagement', '3', 5),(57, 'user_engagement', '4', 7),(58, 'user_engagement', '45', 1),(59, 'user_engagement', '46', 4),(60, 'user_engagement', '47', 2),(61, 'user_engagement', '5', 12),(62, 'user_engagement', '6', 19),(63, 'user_engagement', '61', 1),(64, 'user_engagement', '62', 2),(65, 'user_engagement', '69', 3),(66, 'user_engagement', '7', 10),(67, 'user_engagement', '72', 1),(68, 'user_engagement', '8', 1)
[2024-07-19T14:00:18.267+0000] {base.py:83} INFO - Using connection ID 'postgres_google_analytics' for task execution.
[2024-07-19T14:00:18.276+0000] {base.py:83} INFO - Using connection ID 'postgres_google_analytics' for task execution.
[2024-07-19T14:00:18.278+0000] {taskinstance.py:2699} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/hooks/sql.py", line 385, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/postgres/hooks/postgres.py", line 158, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

[2024-07-19T14:00:18.287+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=google_analytics_data_etl, task_id=task_load_data_postgres, execution_date=20240718T150445, start_date=20240719T140018, end_date=20240719T140018
[2024-07-19T14:00:18.292+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/utils/email.py:154: RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
  send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)

[2024-07-19T14:00:18.293+0000] {configuration.py:1046} WARNING - section/key [smtp/smtp_user] not found in config
[2024-07-19T14:00:18.293+0000] {email.py:270} INFO - Email alerting: attempt 1
[2024-07-19T14:00:18.295+0000] {taskinstance.py:1116} ERROR - Error when executing task_fail_email_alert callback
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2335, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2500, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2517, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/hooks/sql.py", line 385, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/postgres/hooks/postgres.py", line 158, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.3), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1113, in _run_finished_callback
    callback(context)
  File "/opt/airflow/dags/google_analytics_data_etl/google_analytics_data_etl.py", line 34, in task_fail_email_alert
    return send_mail.execute(context=context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/email.py", line 79, in execute
    send_email(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 80, in send_email
    return backend(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 154, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 272, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/email.py", line 316, in _get_smtp_connection
    return smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.8/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.8/smtplib.py", line 339, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.8/smtplib.py", line 310, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/usr/local/lib/python3.8/socket.py", line 808, in create_connection
    raise err
  File "/usr/local/lib/python3.8/socket.py", line 796, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address
[2024-07-19T14:00:18.319+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 250 for task task_load_data_postgres (connection to server at "postgres" (172.18.0.3), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
; 108)
[2024-07-19T14:00:18.347+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-19T14:00:18.362+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
